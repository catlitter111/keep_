# 卷积神经网络 - 填充与步幅详解

在卷积神经网络中，填充（Padding）和步幅（Stride）是两个重要的超参数，它们影响卷积操作的输出尺寸和特性。本笔记将详细解释这两个概念及其实际应用。

## 1. 输出尺寸计算公式

在进行卷积操作时，输出尺寸可以通过以下公式计算：

```
output_size = (input_size - kernel_size + 2*padding)/stride + 1
```

这个公式适用于高度和宽度的计算，其中：
- `input_size`: 输入特征图的尺寸
- `kernel_size`: 卷积核的尺寸
- `padding`: 填充的大小
- `stride`: 步幅大小

## 2. 填充（Padding）

### 2.1 填充的概念

填充是指在输入特征图的周围添加额外的像素（通常为0），目的是：
- 控制输出特征图的空间尺寸
- 保留边缘信息，防止边缘信息在多次卷积后丢失

### 2.2 常见的填充方式

- **无填充（No Padding）**: padding=0
- **半填充（Half Padding）**: padding=kernel_size//2，使输出尺寸与输入尺寸相同
- **全填充（Full Padding）**: padding=kernel_size-1

### 2.3 填充示例代码

```python
import torch
from torch import nn

def comp_conv2d(conv2d, X): # conv2d 作为传参传进去，在内部使用
    X = X.reshape((1,1)+X.shape) # 在维度前面加入一个通道数和批量大小数
    Y = conv2d(X)  # 卷积处理是一个四维的矩阵
    return Y.reshape(Y.shape[2:]) # 将前面两个维度拿掉

# output_size = (input_size - kernel_size + 2*padding)/stride + 1
conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1) # padding=1 为左右都填充一行
X = torch.rand(size=(8,8))
print(comp_conv2d(conv2d,X).shape)
```

输出结果：
```
torch.Size([8, 8])
```

**代码解析**：
1. 首先定义了一个辅助函数`comp_conv2d`，用于简化卷积操作：
   - 将输入张量X重塑为四维形式`(batch_size, channels, height, width)`
   - 应用卷积操作
   - 返回去除批量和通道维度后的结果

2. 创建一个卷积层`nn.Conv2d`：
   - 输入通道数为1
   - 输出通道数为1
   - 卷积核大小为3×3
   - 填充大小为1（在四周各填充1个像素）

3. 输入X为8×8的随机张量

4. 输出尺寸计算：
   - 输入尺寸：8×8
   - 卷积核尺寸：3×3
   - 填充：1
   - 步幅：默认为1
   - 输出尺寸 = (8 - 3 + 2*1)/1 + 1 = 8

### 2.4 不同高度和宽度的填充

PyTorch允许为高度和宽度设置不同的填充值。

```python
conv2d = nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1)) #上下 左右
print(comp_conv2d(conv2d,X).shape)
```

输出结果：
```
torch.Size([8, 8])
```

**代码解析**：
1. 卷积核大小为5×3（高度5，宽度3）
2. 填充大小为(2,1)，表示在高度方向上下各填充2个像素，在宽度方向左右各填充1个像素
3. 输出尺寸计算：
   - 高度方向：(8 - 5 + 2*2)/1 + 1 = 8
   - 宽度方向：(8 - 3 + 2*1)/1 + 1 = 8

## 3. 步幅（Stride）

### 3.1 步幅的概念

步幅是指卷积核在输入特征图上滑动的步长，它决定了卷积核移动的距离。步幅具有以下特点：
- 控制特征图的下采样程度
- 减小输出特征图的空间尺寸
- 增大感受野（receptive field）

### 3.2 步幅为2的示例

```python
# 将高度和宽度的步幅设置为2
conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)
print(comp_conv2d(conv2d,X).shape)
```

输出结果：
```
torch.Size([4, 4])
```

**代码解析**：
1. 卷积核大小为3×3
2. 填充大小为1
3. 步幅为2，表示卷积核每次移动2个像素
4. 输出尺寸计算：
   - (8 - 3 + 2*1)/2 + 1 = 4

**图形化解释**：

假设有一个8×8的输入，使用3×3的卷积核，填充为1，步幅为2：

```
原始输入 (8×8)：
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □
□ □ □ □ □ □ □ □

填充后 (10×10)：
○ ○ ○ ○ ○ ○ ○ ○ ○ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ □ □ □ □ □ □ □ □ ○
○ ○ ○ ○ ○ ○ ○ ○ ○ ○

卷积核从左上角开始，每次移动2个位置，总共产生4×4=16个输出点。
```

### 3.3 不同高度和宽度的步幅

PyTorch同样允许为高度和宽度设置不同的步幅值。

```python
# 一个稍微复杂的例子
conv2d = nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))
print(comp_conv2d(conv2d,X).shape)
```

输出结果：
```
torch.Size([2, 2])
```

**代码解析**：
1. 卷积核大小为3×5（高度3，宽度5）
2. 填充大小为(0,1)，表示在高度方向不填充，在宽度方向左右各填充1个像素
3. 步幅为(3,4)，表示在高度方向步幅为3，在宽度方向步幅为4
4. 输出尺寸计算：
   - 高度方向：(8 - 3 + 2*0)/3 + 1 = 3 (向下取整) = 2
   - 宽度方向：(8 - 5 + 2*1)/4 + 1 = 2

## 4. 填充和步幅的作用总结

### 4.1 填充的作用
- **保持输出尺寸**：通过适当的填充，可以使输出特征图与输入特征图具有相同的空间尺寸
- **保留边缘信息**：没有填充时，边缘像素参与的卷积操作较少，导致边缘信息丢失
- **控制输出尺寸**：通过调整填充大小，可以精确控制输出特征图的尺寸

### 4.2 步幅的作用
- **降低计算量**：增大步幅可以减少输出特征图的尺寸，从而降低后续层的计算量
- **下采样**：步幅大于1时，起到类似池化层的下采样效果
- **增大感受野**：更大的步幅使得每个输出像素对应更大范围的输入区域
- **避免特征冗余**：相邻位置的特征可能高度相似，增大步幅可以减少冗余

## 5. 实际应用建议

### 5.1 常用的填充和步幅组合
- **相同尺寸输出**：kernel_size=k, padding=k//2, stride=1
- **降采样为一半**：kernel_size=k, padding=k//2, stride=2
- **无填充**：kernel_size=k, padding=0, stride=1（输出尺寸会减小）

### 5.2 网络设计考虑
- 浅层网络通常使用较小的步幅，以保留更多的空间信息
- 深层网络中可以逐渐增大步幅，减小特征图尺寸，增加通道数
- 填充通常设置为使输出尺寸为整数，且最好能被后续步幅整除

## 6. 总结

填充和步幅是卷积神经网络中控制特征图尺寸和信息流动的重要参数：

1. **填充**通过在输入周围添加额外像素，保留边缘信息并控制输出尺寸。

2. **步幅**通过控制卷积核的移动步长，实现下采样并减少计算量。

3. 输出尺寸计算公式：`output_size = (input_size - kernel_size + 2*padding)/stride + 1`

4. PyTorch的`nn.Conv2d`允许为高度和宽度方向分别设置不同的卷积核大小、填充和步幅，提供了灵活的网络设计选择。

通过合理设置填充和步幅，可以构建高效且性能良好的卷积神经网络结构。