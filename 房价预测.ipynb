{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载./01_data/02_DataSet_Kaggle_House/kaggle_house_pred_train.csv...\n",
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载./01_data/02_DataSet_Kaggle_House/kaggle_house_pred_test.csv...\n",
      "(1460, 81)\n",
      "(1459, 80)\n",
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "def download(name, cache_dir=os.path.join('.', '01_data/02_DataSet_Kaggle_House')):\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}.\"\n",
    "    url , sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname,'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url,stream=True,verify=True)\n",
    "    with open(fname,'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "    \n",
    "def download_extract(name, folder=None):\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp,extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def download_all():\n",
    "    \"\"\"下载DATA_UHB中的所有文件\"\"\"\n",
    "    for name in DATA_HUB:\n",
    "        download(name)\n",
    "\n",
    "DATA_HUB['kaggle_house_train'] = (DATA_URL + 'kaggle_house_pred_train.csv','585e9cc9370b9160e7921475fbcd7d31219ce')         \n",
    "DATA_HUB['kaggle_house_test'] = (DATA_URL + 'kaggle_house_pred_test.csv', 'fal9780a7b011d9b009e8bff8e99922a8ee2eb90')     \n",
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))\n",
    "print(train_data.shape) # 1460个样本，80个te特征，1个标号label\n",
    "print(test_data.shape) # 测试样本没有标号label\n",
    "\n",
    "print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]]) # 前面四行的某些列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:])) # 从第2列开始，第1列没有了 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "Street            object\n",
      "                  ...   \n",
      "MiscVal            int64\n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "Length: 79, dtype: object\n",
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 将所有缺失的值替换成相应特征的平均值\n",
    "# 通过将特征重新缩放到零均值和单位方差来标准化数据\n",
    "print(all_features.dtypes) # 可以知道每一列分别为什么类型特征\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index  # 当值的类型不是object的话，就是一个数值\n",
    "print(numeric_features)\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std())) # 对数值数据变为总体为均值为0，方差为1的分布的数据        \n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)  # 将数值数据中not number的数据用0填充      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 330)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理离散值。用一次独热编码替换它们\n",
    "# 若一列里面有五个不同的值，则创建五个features，如果该列中为该feature则为1，不为该feature则为0\n",
    "all_features = pd.get_dummies(all_features,dummy_na=True) \n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_train \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# 样本个数\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(all_features[n_train:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m      5\u001b[0m                              dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# train_data的SalePrice列是label值\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "n_train = train_data.shape[0] # 样本个数\n",
    "train_features = torch.tensor(all_features[:n_train].values,\n",
    "                              dtype=torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values,\n",
    "                             dtype=torch.float32)\n",
    "# train_data的SalePrice列是label值\n",
    "train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1,1),\n",
    "                            dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
